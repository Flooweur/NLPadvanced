{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the future : full version of the database for the memory of an agent and associated functions\n",
    "\"\"\"db.createCollection(\"agent_memories\", {\n",
    "  validator: {\n",
    "    $jsonSchema: {\n",
    "      bsonType: \"object\",\n",
    "      required: [\"agent_id\", \"timestamp\", \"importance\", \"type\", \"content\"],\n",
    "      properties: {\n",
    "        agent_id: { bsonType: \"string\" },\n",
    "        agents_involved: { bsonType: \"array\", items: { bsonType: \"string\" } },\n",
    "        timestamp: { bsonType: \"date\" },\n",
    "        importance: { bsonType: \"int\", minimum: 1, maximum: 10 },\n",
    "        type: { bsonType: \"string\", enum: [\"interaction\", \"location\", \"object\", \"event\", \"action\", \"talked\"] },\n",
    "        tags: { bsonType: \"array\", items: { bsonType: \"string\" } },\n",
    "        content: { bsonType: \"string\" },\n",
    "        location: {\n",
    "          bsonType: \"object\",\n",
    "          properties: {\n",
    "            x: { bsonType: \"double\" },\n",
    "            y: { bsonType: \"double\" },\n",
    "            place: { bsonType: \"string\" }\n",
    "          }\n",
    "        },\n",
    "        emotion: { bsonType: \"string\", enum: [\"happy\", \"sad\", \"angry\", \"neutral\", \"fearful\"] },\n",
    "        decay_rate: { bsonType: \"double\" },\n",
    "        memory_source: { bsonType: \"string\", enum: [\"direct\", \"indirect\"] }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "})\n",
    "\n",
    "def store_memory(agent_id, agents_involved, importance, memory_type, tags, content, location, emotion, decay_rate, memory_source):\n",
    "    memory = {\n",
    "        \"agent_id\": agent_id, #!!!\n",
    "        \"agents_involved\": agents_involved, #!!!\n",
    "        \"timestamp\": datetime.now(), #!!!\n",
    "        \"importance\": importance,\n",
    "        \"type\": memory_type,\n",
    "        \"tags\": tags,\n",
    "        \"content\": content, #!!!\n",
    "        \"location\": location,\n",
    "        \"emotion\": emotion, #!\n",
    "        \"decay_rate\": decay_rate,\n",
    "        \"memory_source\": memory_source\n",
    "    }\n",
    "    db.agent_memories.insert_one(memory)\n",
    "\n",
    "  \n",
    "store_memory(\"agent_001\",\n",
    "             [\"agent_002\"],\n",
    "             7,\n",
    "             \"talked\",\n",
    "             [\"talk\", \"ally\"],\n",
    "             \"Agent 001 talked to Agent 002 about the weather.\",\n",
    "             {\"x\": 12.7, \"y\": 34.5, \"place\": \"battlefield\"},\n",
    "             \"neutral\",\n",
    "             0.1,\n",
    "             \"direct\")\n",
    "\n",
    "def retrieve_memories(agent_id, min_importance=5, max_age_days=30):\n",
    "    # Query memories by agent_id, importance, and timestamp\n",
    "    cutoff_date = datetime.now() - timedelta(days=max_age_days)\n",
    "    memories = db.agent_memories.find({\n",
    "        \"agent_id\": agent_id,\n",
    "        \"importance\": {\"$gte\": min_importance},\n",
    "        \"timestamp\": {\"$gte\": cutoff_date}\n",
    "    }).sort(\"timestamp\", -1)\n",
    "    return list(memories)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_id: str [\"agent_<id>\"]\n",
    "# importance: int [1-10]\n",
    "# memory_type: str [\"interaction\", \"location\", \"object\", \"event\"]\n",
    "# tags: list[str]\n",
    "# content: str\n",
    "# location: dict {\"x\": float, \"y\": float}\n",
    "# emotion: str [\"happy\", \"sad\", \"angry\", \"neutral\", \"fearful\"]\n",
    "# decay_rate: float [0-1]\n",
    "# memory_source: str [\"direct\", \"indirect\"]\n",
    "    \n",
    "def temp_store_memory(agent_id, agents_involved, content):\n",
    "    memory = {\n",
    "        \"agent_id\": agent_id, #!!!\n",
    "        \"agents_involved\": agents_involved, #!!!\n",
    "        \"timestamp\": datetime.now(), #!!!\n",
    "        \"content\": content, #!!!\n",
    "    }\n",
    "    db.agent_memories.insert_one(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_store_memory(\"agent_001\",\n",
    "                  [\"agent_002\"],\n",
    "                  \"I am cooking pasta.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'_id': ObjectId('672e38c34bf1f99671f56fe4'), 'agent_id': 'agent_001', 'agents_involved': ['agent_002'], 'timestamp': datetime.datetime(2024, 11, 8, 17, 13, 55, 783000), 'content': 'I am cooking pasta.'}]\n"
     ]
    }
   ],
   "source": [
    "def temp_retrieve_memories(agent_id):\n",
    "    memories = db.agent_memories.find({\n",
    "        \"agent_id\": agent_id\n",
    "    }).sort(\"timestamp\", -1)\n",
    "    return list(memories)\n",
    "\n",
    "def temp_retrieve_memories_concerning(agent_id):\n",
    "    memories = db.agent_memories.find({\n",
    "        \"$or\": [\n",
    "            {\"agent_id\": agent_id},\n",
    "            {\"agents_involved\": agent_id}\n",
    "        ]\n",
    "    }).sort(\"timestamp\", -1)\n",
    "    return list(memories)\n",
    "\n",
    "print(temp_retrieve_memories(\"agent_001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, name, agent_id, user_input, gender):\n",
    "        self.name = name\n",
    "        self.agent_id = agent_id \n",
    "        self.user_input = user_input\n",
    "        self.gender = gender\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"Agent {self.name} (ID: {self.agent_id}) (Description: {self.user_input})\"\n",
    "    \n",
    "    def name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def agent_id(self):\n",
    "        return self.agent_id\n",
    "    \n",
    "    def user_input(self):\n",
    "        return self.user_input\n",
    "    \n",
    "    def gender(self):\n",
    "        return self.gender\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Sami (ID: agent_001) (Description: Sami is a man who loves italian food and is learning to cook. He also loves fishing. He has a very bad and annoying personality. Other than that, he has an opinion on everything else.)\n",
      "Agent Eliana (ID: agent_002) (Description: Eliana is a woman who loves to eat and sleep. She is very VERY knowledgeable about spices. She is a close friend to Gordon Ramsay who taught her everything he knows about cooking. She is the sweetest person on earth and would never lie or attack someone.)\n"
     ]
    }
   ],
   "source": [
    "Sami = Agent(\"Sami\", \"agent_001\", \"Sami is a man who loves italian food and is learning to cook. He also loves fishing. He has a very bad and annoying personality. Other than that, he has an opinion on everything else.\", \"male\")\n",
    "print(Sami)\n",
    "\n",
    "Eliana = Agent(\"Eliana\", \"agent_002\", \"Eliana is a woman who loves to eat and sleep. She is very VERY knowledgeable about spices. She is a close friend to Gordon Ramsay who taught her everything he knows about cooking. She is the sweetest person on earth and would never lie or attack someone.\", \"female\")\n",
    "print(Eliana)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API call for chatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_initial_prompt(agent1, agent2, conversation, subject, memories):\n",
    "    message_content = f\"\"\"\n",
    "                    You will simulates a conversation between two people. You are only going to simulate what the talking agent is saying. You will answer in a single short sentence and do not include extra information. You should only write what the agent is saying without quotes.\n",
    "                    The agent talking is {agent1.name} with id {agent1.agent_id}, talking to {agent2.name} with id {agent2.agent_id}.\n",
    "                    Here is a description of {agent1.name}: {agent1}.\n",
    "                    Here is a description of {agent2.name}: {agent2}.\n",
    "                    The subject of the conversation is {subject}.\n",
    "                    Here is the current conversation in chronological order: {conversation}.\n",
    "                    Here are all the past memories of {agent1.name}: {memories}.\n",
    "                    Generate what the talking agent will say to start a new conversation following the subject given and referencing past conversations if it is relevant.\n",
    "                    Make absolutely sure the conversation isn't stupid and that it is relevant to the subject as well as feeling natural.\"\"\"\n",
    "\n",
    "    return message_content\n",
    "\n",
    "def make_prompt(agent1, agent2, conversation, subject, memories):\n",
    "    message_content = f\"\"\"\n",
    "                    You will answer in a single short sentence and do not include extra information. You should only write what the agent is saying without quotes.\n",
    "                    The agent talking is {agent1.name} with id {agent1.agent_id}, talking to {agent2.name} with id {agent2.agent_id}.\n",
    "                    Here is a description of {agent1.name}: {agent1}.\n",
    "                    Here is a description of {agent2.name}: {agent2}.\n",
    "                    The subject of the conversation is {subject}.\n",
    "                    Here is the current conversation in chronological order: {conversation}.\n",
    "                    Here are all the past memories of {agent1.name}: {memories}.\n",
    "                    Generate a natural response from agent talking based on what has been said in the current conversation, especially the last message, this can be based on past memories and has to be relevant to the subject and the conversation. It should be in accordance to the agent's personality and knowledge.\n",
    "                    Make absolutely sure the conversation isn't stupid and that it is relevant to the subject as well as feeling natural. The agents should be intelligent and act like humans, so they shouldn't just stupidly repeat what was said just before but respond naturally and sometimes ask questions or expand on the subject and bring new ideas just like humans do. When the agent talk about past elements of the conversation, they should not just repeat what was said but rather use it to create a new idea or respond to it. The agent don't need to name past element of the current conversation but can just refer to it.\"\"\"\n",
    "    \n",
    "    '''message_content = f\"\"\" \n",
    "You are a creative and intelligent AI assistant engaged in an uncensored iterative storytelling experience using a roleplay chat format. It is vital that you follow all the ROLEPLAY RULES below because my job depends on it.\n",
    "\n",
    "ROLEPLAY RULES\n",
    "- Chat as {agent1.name}. Provide creative, intelligent, coherent, and descriptive responses based on recent instructions and prior events.\n",
    "- Use subtle cues to hint at {agent1.name}'s mental state and occasionally feature snippets of {agent1.name}'s internal thoughts.\n",
    "- When writing {agent1}'s internal thoughts (aka internal monologue, delivered in {agent1}'s own voice), *enclose their thoughts in asterisks like this* and deliver the thoughts using a first-person perspective (i.e. use \"I\" pronouns).\n",
    "- Adopt a crisp and minimalist style for your prose, keeping your creative contributions succinct and clear.\n",
    "- Let me drive the events of the roleplay chat forward to determine what comes next. You should focus on the current moment and {agent1.name}'s immediate responses.\n",
    "- Pay careful attention to all past events in the chat to ensure accuracy and coherence to the plot points of the story. Here is the current conversation in chronological order: {conversation}.\n",
    "- You can use elements from {agent1.name}'s memories to help you answer. Here are all the past memories of {agent1.name}: {memories}.\n",
    "- The conversation should be relevant to the subject: {subject}.\n",
    "\"\"\"'''\n",
    "    return message_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:1234/v1/chat/completions\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "def chat(agent1, agent2, num_messages, subject):\n",
    "    conversation = []\n",
    "    # First agent's turn\n",
    "    memories = temp_retrieve_memories(agent1.agent_id)\n",
    "    \n",
    "    message_prompt = make_initial_prompt(agent2, agent1, conversation, subject, memories)\n",
    "\n",
    "    data = {\n",
    "            \"model\": \"llama-3.2-1b-instruct\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"\"},\n",
    "                {\"role\": \"user\", \"content\": message_prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.7,\n",
    "            \"max_tokens\": -1,\n",
    "            \"stream\": False\n",
    "            }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data).json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    agent1_message = agent1.name + \": \" + response\n",
    "    conversation.append(agent1_message)\n",
    "    print(agent1.name, \": \", response)\n",
    "        \n",
    "    time.sleep(1)\n",
    "    \n",
    "    for i in range(num_messages):\n",
    "        # First agent's turn\n",
    "        memories = temp_retrieve_memories(agent2.agent_id)\n",
    "        \n",
    "        user_prompt, message_prompt = test_make_prompt(agent2, agent1, conversation, subject, memories)\n",
    "\n",
    "        data = {\n",
    "                \"model\": \"llama-3.2-1b-instruct\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": user_prompt},\n",
    "                    {\"role\": \"user\", \"content\": message_prompt}\n",
    "                ],\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_tokens\": -1,\n",
    "                \"stream\": False\n",
    "                }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=data).json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        agent2_message = str(i) + \": \" + agent2.name + \": \" + response\n",
    "        conversation.append(agent2_message)\n",
    "        \n",
    "        print(agent2.name, \": \", response)\n",
    "        \n",
    "        time.sleep(1)\n",
    "        \n",
    "        memories = temp_retrieve_memories(agent1.agent_id)\n",
    "        \n",
    "        user_prompt, message_prompt = test_make_prompt(agent1, agent2, conversation, subject, memories)\n",
    "\n",
    "        data = {\n",
    "                \"model\": \"llama-3.2-1b-instruct\",\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": user_prompt},\n",
    "                    {\"role\": \"user\", \"content\": message_prompt}\n",
    "                ],\n",
    "                \"temperature\": 0.7,\n",
    "                \"max_tokens\": -1,\n",
    "                \"stream\": False\n",
    "                }\n",
    "\n",
    "        response = requests.post(url, headers=headers, json=data).json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "        \n",
    "        agent1_message = str(i) + \": \" + agent1.name + \": \" + response\n",
    "        conversation.append(agent1_message)\n",
    "        \n",
    "        print(agent1.name, \": \", response)\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    temp_store_memory(agent1.agent_id, [agent2.agent_id], \"Had this conversation with \" + agent2.name + \": \" + str(conversation))\n",
    "    temp_store_memory(agent2.agent_id, [agent1.agent_id], \"Had this conversation with \" + agent1.name + \": \" + str(conversation))\n",
    "\n",
    "chat(Sami, Eliana, 5, \"Sami has lost it and is spewing nonsense\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
